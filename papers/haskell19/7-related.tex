\section{Related Work}
\label{sec:related}

\citeauthor{SwierstraDTC} proposed Data Types \`a la Carte \cite{SwierstraDTC},
a technique for building extensible data types, as a solution for the
\emph{expression problem}, coined by \citeauthor{wadler1998expression}
\cite{wadler1998expression}.
%
This technique has been successfully applied in a variety of scenarios, from
extensible compilers, to composable machine-mechanized proofs
\cite{Day:2013:CAL:2620678.2620680, persson2011generic, wu2014effect,
  delaware2013meta}.
%
In this work, we take ideas from this approach and extend them to work in the
scope of random data generation, where other parameters come into play apart
from just combining constructions, e.g., generation frequency and terminal
constructions.


From the practical point of view, \citeauthor{KiriyamaOptimizingDTC} propose an
optimization mechanism for Data Types \`a Carte, where a concrete data type has
to be derived for each different composition of constructions defined by the
user \cite{KiriyamaOptimizingDTC}.
%
This solution avoids much of the runtime overhead introduced when internally
pattern matching against sequences of |InL| and |InR| data constructors.
%
However, we see this solution as not entirely compositional, since we still need
to rely on Template Haskell to derive the machinery for each specialized data
type.
%
In our particular setting, we found that our solution has a fairly acceptable
overhead, achieved by automatically balancing our representation types.


In the past few years, there has been a bloom of derivation tools for
synthesizing random generators.
%
\emph{Feat} provides a mechanism to uniformly generating values from a given
data type \cite{DuregardJW12}.
%
It works by enumerating all the possible values of such type, so that sampling
uniformly from it simply becomes sampling uniformly from a finite prefix of
natural numbers---something easy to do.


\emph{MegaDeTH} is a simple derivation tool that synthesizes generators solely
based on their types, paying no attention whatsoever to the generation frequency
of each data constructor.
%
As a result, its automatically derived generators has been shown to be skewed
towards generating very small values
\cite{DBLP:conf/haskell/MistaRH18}.\looseness=-1


On the other hand, \emph{DRAGEN} is a tool that synthesizes optimized
generators, tuning their generation frequencies using a simulation-based
optimization process, which is parameterized by the distribution of values
desired by the user \cite{DBLP:conf/haskell/MistaRH18}.
%
This simulation is based on the theory of \emph{branching processes}, which
models the growth and extinction of populations across successive generations.
%
In this setting, populations consist of randomly generated data constructors,
where generations correspond to each level of the generated values.
%
This tool has shown to improve the code coverage over complex systems, when
compared to other fully-automated generators derivation mechanisms.
%
In a recent work, the authors extended this approach to generate random values
considering also the other sources of structural information covered here,
namely abstract interfaces and function pattern matchings.
%
There, they focus on the generation model problem, extending the theory of
branching processes in order to obtain sound predictions about distributions of
random values considering these new kinds of constructions.
%
Using this extension, they show that using extra information when generating
random values is extremely valuable, in particular under situations like the
ones described in Section \ref{sec:sources}, where the usual derivation
approaches fail to synthesize useful generators due to a lack of structural
information.


In turn, this paper tackles the representation problem, demonstrating how a
compositional generation process can be effectively implemented and automated in
Haskell using advanced type-level features.
%
Since none of the aforementioned tools are designed for composability, we
consider that our ideas could perhaps be applied to improve these tools in the
future.
